{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4+nnRy2JiS1wV3aZTzRZS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khushal21csu188/RLLAB-SEM-5/blob/main/RL%20Exp-4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GREEDY**"
      ],
      "metadata": {
        "id": "BoJIyO4zLLTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajgSDFCALHxW",
        "outputId": "28f11e9c-de8c-40b0-ab90-d8d2dc4d963d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward using Greedy Approach: 10.0\n",
            "Lamp chosen 1\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def greedy_approach(lamp_durations):\n",
        "    best_lamp = None\n",
        "    max_duration = 0\n",
        "\n",
        "    for lamp, duration in enumerate(lamp_durations):\n",
        "        if duration > max_duration:\n",
        "            max_duration = duration\n",
        "            best_lamp = lamp\n",
        "\n",
        "    return best_lamp\n",
        "\n",
        "num_lamps = 5\n",
        "lamp_durations = [random.randint(1, 10) for i in range(num_lamps)]  # Generate random durations\n",
        "steps = 1000\n",
        "\n",
        "total_reward = 0\n",
        "for i in range(steps):\n",
        "    chosen_lamp = greedy_approach(lamp_durations)\n",
        "    reward = lamp_durations[chosen_lamp]\n",
        "    total_reward += reward\n",
        "\n",
        "average_reward = total_reward / steps\n",
        "print(\"Average reward using Greedy Approach:\", average_reward)\n",
        "print(\"Lamp chosen\",chosen_lamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIMISTIC GREEDY**"
      ],
      "metadata": {
        "id": "zUpVOcFTL-dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def optimistic_approach(lamp_durations):\n",
        "    num_lamps = len(lamp_durations)\n",
        "    estimated_durations = [10] * num_lamps  # Initialize with optimistic estimates\n",
        "    chosen_lamp = None\n",
        "\n",
        "    for lamp, _ in enumerate(lamp_durations):\n",
        "        observed_duration = random.randint(1, 10)  # Generate random observed duration\n",
        "        estimated_durations[lamp] = observed_duration\n",
        "\n",
        "    for _ in range(steps):\n",
        "        chosen_lamp = estimated_durations.index(max(estimated_durations))\n",
        "        reward = lamp_durations[chosen_lamp]\n",
        "        observed_duration = random.randint(1, 10)  # Generate random observed duration\n",
        "        estimated_durations[chosen_lamp] = (estimated_durations[chosen_lamp] + observed_duration) / 2\n",
        "\n",
        "    return chosen_lamp\n",
        "\n",
        "num_lamps = 5\n",
        "lamp_durations = [random.randint(1, 10) for _ in range(num_lamps)]  # Generate random durations\n",
        "steps = 1000\n",
        "\n",
        "total_reward = 0\n",
        "for _ in range(steps):\n",
        "    chosen_lamp = optimistic_approach(lamp_durations)\n",
        "    reward = lamp_durations[chosen_lamp]\n",
        "    total_reward += reward\n",
        "\n",
        "average_reward = total_reward / steps\n",
        "print(\"Average reward using Optimistic Approach:\", average_reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTVJUmxnMByN",
        "outputId": "c4633ec6-151e-4498-aba6-0cee32c595fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward using Optimistic Approach: 4.668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EPSILON**"
      ],
      "metadata": {
        "id": "ojeiDKFeMPH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def epsilon_greedy_approach(lamp_durations, epsilon):\n",
        "    num_lamps = len(lamp_durations)\n",
        "    chosen_lamp = None\n",
        "\n",
        "    for _ in range(steps):\n",
        "        if random.random() < epsilon:\n",
        "            chosen_lamp = random.randint(0, num_lamps - 1)\n",
        "        else:\n",
        "            chosen_lamp = lamp_durations.index(max(lamp_durations))\n",
        "        reward = lamp_durations[chosen_lamp]\n",
        "        observed_duration = random.randint(1, 10)  # Generate random observed duration\n",
        "        lamp_durations[chosen_lamp] = (lamp_durations[chosen_lamp] + observed_duration) / 2\n",
        "\n",
        "    return chosen_lamp\n",
        "\n",
        "num_lamps = 5\n",
        "lamp_durations = [random.randint(1, 10) for _ in range(num_lamps)]  # Generate random durations\n",
        "steps = 1000\n",
        "exploration_probability = 0.1  # Set epsilon value\n",
        "\n",
        "total_reward = 0\n",
        "for _ in range(steps):\n",
        "    chosen_lamp = epsilon_greedy_approach(lamp_durations, exploration_probability)\n",
        "    reward = lamp_durations[chosen_lamp]\n",
        "    total_reward += reward\n",
        "\n",
        "average_reward = total_reward / steps\n",
        "print(\"Average reward using Epsilon-Greedy Approach:\", average_reward)\n"
      ],
      "metadata": {
        "id": "jVLgW3yRMTGA",
        "outputId": "f1462d74-558b-49f2-a1e6-a51d4763c731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward using Epsilon-Greedy Approach: 5.530795493411025\n"
          ]
        }
      ]
    }
  ]
}